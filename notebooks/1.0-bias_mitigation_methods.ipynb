{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias mitigation methods\n",
    "\n",
    "In a perfect world, you should start thinking about fairness at the data collection level. However, in many real-life situations, the dataset has already been prepared, the features have already been extracted or even the model has already been trained. Don’t worry, in each of those situations you can apply de-biasing techniques to make your model fairer.\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "The bias is removed from the data before training the model. One example is Learning Fair Representation where the original features are transformed to a fair, latent space. It lets you mitigate bias at the data level and use any framework you like for modeling. The problem is that bias is often hidden across many features and truly removing it is just hard in practice.\n",
    "\n",
    "<img src=\"../images/pre-processing.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "## Inprocessing\n",
    "\n",
    "The information about sensitive features is used to guide model training. An interesting approach is Adversarial De-biasing where apart from the original task of predicting a class the model is also predicting the sensitive feature and is penalized for doing it correctly. It brings a lot of promise and seems to be working pretty well. However, there is only a very limited amount of frameworks/projects at your disposal.\n",
    "\n",
    "<img src=\"../images/in-processing.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "## Postprocessing\n",
    "\n",
    "The predictions of the model are adjusted to minimize some fairness metric. For example, one can reweigh predictions to make the prediction distribution for privileged and unprivileged group equal and hence minimize the equal opportunity metric. It lets you use all the tools you want and allows you to apply fixes post-hoc but it doesn’t work with many fairness metrics.\n",
    "\n",
    "<img src=\"../images/post-processing.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_fairness",
   "language": "python",
   "name": "model_fairness"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
