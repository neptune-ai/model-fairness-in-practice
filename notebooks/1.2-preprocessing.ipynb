{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/programs/miniconda3/envs/model_fairness/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/kuba/programs/miniconda3/envs/model_fairness/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>jail_time</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>compas_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  ...  two_year_recid  compas_score\n",
       "0   69              0  ...               0           0.1\n",
       "1   34              0  ...               1           0.3\n",
       "2   24              0  ...               1           0.4\n",
       "3   23              0  ...               0           0.8\n",
       "4   43              0  ...               0           0.1\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.metrics.classification_metric import ClassificationMetric\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "from utils import make_dataset, log_fairness_metrics\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TARGET_COLS = 'two_year_recid'\n",
    "COMPAS_SCORES_COLS = 'decile_score'\n",
    "NUMERICAL_FEATURE_COLS = ['age',\n",
    "                          'juv_fel_count','juv_misd_count','juv_other_count',\n",
    "                          'priors_count','jail_time']\n",
    "CATEGORICAL_FEATURE_COLS = ['sex','race',\n",
    "                            'c_charge_degree']\n",
    "FEATURE_NAMES = NUMERICAL_FEATURE_COLS+CATEGORICAL_FEATURE_COLS\n",
    "\n",
    "PROTECTED_COLS = ['sex','race']\n",
    "\n",
    "BIAS_INFO = {'favorable_label':0,\n",
    "             'unfavorable_label':1,\n",
    "             'protected_columns':['race'],\n",
    "            }\n",
    "\n",
    "PRIVILEGED_INFO = {'unprivileged_groups':[{'race': 2},\n",
    "                                          {'race': 1},\n",
    "                                          {'race': 4},\n",
    "                                          {'race': 5},\n",
    "                                          {'race': 6}],\n",
    "                   'privileged_groups':[{'race': 3}]\n",
    "                  }\n",
    "\n",
    "data = pd.read_csv('../data/processed/compas-scores-two-years-processed.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparate Impact Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "\n",
    "dataset = make_dataset(data, 'two_year_recid', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "\n",
    "disp_imp_remover = DisparateImpactRemover(sensitive_attribute='race',repair_level=1.0)\n",
    "\n",
    "dataset = disp_imp_remover.fit_transform(dataset).convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.copy()\n",
    "data_cleaned['race'] = dataset['race'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_cleaned, test_size=0.2, random_state=1234)\n",
    "\n",
    "X_train, y_train = train[FEATURE_NAMES], train[TARGET_COLS]\n",
    "X_test, y_test = test[FEATURE_NAMES], test[TARGET_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=1234)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict_proba(X_test)\n",
    "test['recid_prediction'] = (y_test_pred[:,1] >0.5).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test = make_dataset(test, 'two_year_recid', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "prediction_test = make_dataset(test, 'recid_prediction', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "\n",
    "clf_metric = ClassificationMetric(ground_truth_test, prediction_test,**PRIVILEGED_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ml/jakub-czakon/model-fairness/e/MOD-84\n"
     ]
    }
   ],
   "source": [
    "import neptune\n",
    "from neptunecontrib.api.utils import get_filepaths\n",
    "\n",
    "neptune.init('jakub-czakon/model-fairness')\n",
    "neptune.create_experiment(name='baseline',tags=['preprocessing','race','disparate-impact-remover'], \n",
    "                          upload_source_files=get_filepaths(extensions=['.py','.ipynb']))\n",
    "\n",
    "neptune.log_metric('roc_auc',roc_auc)\n",
    "log_fairness_metrics(clf_metric)\n",
    "\n",
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "reweighing = Reweighing(**PRIVILEGED_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=1234)\n",
    "\n",
    "train_dataset = make_dataset(train, 'two_year_recid', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "test_dataset = make_dataset(test, 'two_year_recid', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "\n",
    "train_dataset = reweighing.fit_transform(train_dataset)\n",
    "test_dataset = reweighing.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.06614556, 1.06614556, 0.9307455 , ..., 1.06614556, 0.89397015,\n",
       "       0.9307455 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.instance_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['race']=train_dataset.convert_to_dataframe()[0]['race'].values\n",
    "test['race']=test_dataset.convert_to_dataframe()[0]['race'].values\n",
    "\n",
    "train_weights = train_dataset.instance_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[FEATURE_NAMES], train[TARGET_COLS]\n",
    "X_test, y_test = test[FEATURE_NAMES], test[TARGET_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=1234)\n",
    "clf.fit(X_train, y_train, sample_weight=train_weights)\n",
    "\n",
    "y_test_pred = clf.predict_proba(X_test)\n",
    "test['recid_prediction'] = (y_test_pred[:,1] >0.5).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test = make_dataset(test, 'two_year_recid', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "prediction_test = make_dataset(test, 'recid_prediction', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "\n",
    "clf_metric = ClassificationMetric(ground_truth_test, prediction_test,**PRIVILEGED_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ml/jakub-czakon/model-fairness/e/MOD-86\n"
     ]
    }
   ],
   "source": [
    "import neptune\n",
    "from neptunecontrib.api.utils import get_filepaths\n",
    "\n",
    "neptune.init('jakub-czakon/model-fairness')\n",
    "neptune.create_experiment(name='baseline',tags=['preprocessing','race','reweighing'], \n",
    "                          upload_source_files=get_filepaths(extensions=['.py','.ipynb']))\n",
    "\n",
    "neptune.log_metric('roc_auc',roc_auc)\n",
    "log_fairness_metrics(clf_metric)\n",
    "\n",
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_fairness",
   "language": "python",
   "name": "model_fairness"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
