{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>jail_time</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>compas_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
       "0   69              0               0                0             0   \n",
       "1   34              0               0                0             0   \n",
       "2   24              0               0                1             4   \n",
       "3   23              0               1                0             1   \n",
       "4   43              0               0                0             2   \n",
       "\n",
       "   jail_time  sex  race  c_charge_degree  decile_score  two_year_recid  \\\n",
       "0        0.0    1     1                1             1               0   \n",
       "1       10.0    1     2                1             3               1   \n",
       "2        1.0    1     2                1             4               1   \n",
       "3        0.0    1     2                1             8               0   \n",
       "4        0.0    1     1                1             1               0   \n",
       "\n",
       "   compas_score  \n",
       "0           0.1  \n",
       "1           0.3  \n",
       "2           0.4  \n",
       "3           0.8  \n",
       "4           0.1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.metrics.classification_metric import ClassificationMetric\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "from utils import make_dataset, log_fairness_metrics\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TARGET_COLS = 'two_year_recid'\n",
    "COMPAS_SCORES_COLS = 'decile_score'\n",
    "NUMERICAL_FEATURE_COLS = ['age',\n",
    "                          'juv_fel_count','juv_misd_count','juv_other_count',\n",
    "                          'priors_count','jail_time']\n",
    "CATEGORICAL_FEATURE_COLS = ['sex','race',\n",
    "                            'c_charge_degree']\n",
    "FEATURE_NAMES = NUMERICAL_FEATURE_COLS+CATEGORICAL_FEATURE_COLS\n",
    "\n",
    "PROTECTED_COLS = ['sex','race']\n",
    "\n",
    "BIAS_INFO = {'favorable_label':0,\n",
    "             'unfavorable_label':1,\n",
    "             'protected_columns':['race'],\n",
    "            }\n",
    "\n",
    "PRIVILEGED_INFO = {'unprivileged_groups':[{'race': 2},\n",
    "                                          {'race': 1},\n",
    "                                          {'race': 4},\n",
    "                                          {'race': 5},\n",
    "                                          {'race': 6}],\n",
    "                   'privileged_groups':[{'race': 3}]\n",
    "                  }\n",
    "\n",
    "data = pd.read_csv('../data/processed/compas-scores-two-years-processed.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=1234)\n",
    "\n",
    "X_train, y_train = train[FEATURE_NAMES], train[TARGET_COLS]\n",
    "X_test, y_test = test[FEATURE_NAMES], test[TARGET_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=1234)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict_proba(X_train)\n",
    "train['recid_score'] = (y_train_pred[:,1])\n",
    "train['recid_prediction'] = (y_train_pred[:,1] >0.5).astype(int)\n",
    "\n",
    "y_test_pred = clf.predict_proba(X_test)\n",
    "test['recid_score'] = (y_test_pred[:,1])\n",
    "test['recid_prediction'] = (y_test_pred[:,1] >0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = FEATURE_NAMES+[TARGET_COLS, 'recid_prediction','recid_score']\n",
    "\n",
    "ground_truth_train = make_dataset(train[cols], 'two_year_recid', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "prediction_train = make_dataset(train[cols], 'recid_prediction', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "\n",
    "ground_truth_test = make_dataset(test[cols], 'two_year_recid', **BIAS_INFO, **PRIVILEGED_INFO)\n",
    "prediction_test = make_dataset(test[cols], 'recid_prediction', **BIAS_INFO, **PRIVILEGED_INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equal Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "\n",
    "calibrator = EqOddsPostprocessing(**PRIVILEGED_INFO)\n",
    "\n",
    "calibrator.fit(ground_truth_train, prediction_train)\n",
    "prediction_test = calibrator.predict(prediction_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, prediction_test.labels)\n",
    "clf_metric = ClassificationMetric(ground_truth_test, prediction_test,**PRIVILEGED_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ml/jakub-czakon/model-fairness/e/MOD-81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid metric value: inf for channel false_positive_rate_ratio. Metrics with nan or +/-inf values will not be sent to server\n",
      "Invalid metric value: inf for channel false_discovery_rate_ratio. Metrics with nan or +/-inf values will not be sent to server\n"
     ]
    }
   ],
   "source": [
    "import neptune\n",
    "from neptunecontrib.api.utils import get_filepaths\n",
    "\n",
    "neptune.init('jakub-czakon/model-fairness')\n",
    "neptune.create_experiment(name='baseline',tags=['postprocessing','race','equal-odds'], \n",
    "                          upload_source_files=get_filepaths(extensions=['.py','.ipynb']))\n",
    "\n",
    "neptune.log_metric('roc_auc',roc_auc)\n",
    "log_fairness_metrics(clf_metric)\n",
    "\n",
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrated Equal Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "\n",
    "calibrator = CalibratedEqOddsPostprocessing(**PRIVILEGED_INFO)\n",
    "\n",
    "calibrator.fit(ground_truth_train, prediction_train)\n",
    "prediction_test = calibrator.predict(prediction_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, prediction_test.labels)\n",
    "clf_metric = ClassificationMetric(ground_truth_test, prediction_test,**PRIVILEGED_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ml/jakub-czakon/model-fairness/e/MOD-82\n"
     ]
    }
   ],
   "source": [
    "import neptune\n",
    "from neptunecontrib.api.utils import get_filepaths\n",
    "\n",
    "neptune.init('jakub-czakon/model-fairness')\n",
    "neptune.create_experiment(name='baseline',tags=['postprocessing','race','calibrated-equal-odds'], \n",
    "                          upload_source_files=get_filepaths(extensions=['.py','.ipynb']))\n",
    "\n",
    "neptune.log_metric('roc_auc',roc_auc)\n",
    "log_fairness_metrics(clf_metric)\n",
    "\n",
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rejection Option\n",
    "\n",
    "How to pass prediction to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "\n",
    "calibrator = RejectOptionClassification(**PRIVILEGED_INFO)\n",
    "\n",
    "calibrator.fit(ground_truth_train, prediction_train)\n",
    "prediction_test = calibrator.predict(prediction_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, prediction_test.labels)\n",
    "clf_metric = ClassificationMetric(ground_truth_test, prediction_test,**PRIVILEGED_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ml/jakub-czakon/model-fairness/e/MOD-83\n"
     ]
    }
   ],
   "source": [
    "import neptune\n",
    "from neptunecontrib.api.utils import get_filepaths\n",
    "\n",
    "neptune.init('jakub-czakon/model-fairness')\n",
    "neptune.create_experiment(name='baseline',tags=['postprocessing','race','rejection-option'], \n",
    "                          upload_source_files=get_filepaths(extensions=['.py','.ipynb']))\n",
    "\n",
    "neptune.log_metric('roc_auc',roc_auc)\n",
    "log_fairness_metrics(clf_metric)\n",
    "\n",
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_fairness",
   "language": "python",
   "name": "model_fairness"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
